1. Key Insight
   - 이미지 사이즈를 인풋으로 넣었을 때 그에 상응하는 사이즈의 아웃풋을 생성하는 Fully Convolutional Network이다.
   - 기존의 Classification 모델(Pretrained Model)에서 앞단은 그대로 재활용하나 뒷단의 Fully Connected Layer를 거치지 않고 
     Fully Convolutional Network를 거친다. 따라서 이미지의 분류를 라벨링에 대한 분류가 아닌 공간에 대한 분류를 갖게되는 것이다.
   - 최근 UNet이 더 좋은 성능을 보인다.
   - 특징
     1) Spatial Dimension
        AlexNet, VGGNet을 그대로 이용하나 Layer의 하위 단에 Fully Connected Layer 대신 Fully Convolutional Network를 사용한다.
        위와 같은 방식을 통하여 Input Data의 Spatial Dimension에 대하여 상응하는 정보를 유지하고자 하였다ㅏ. 
        여기서 Spatial Dimension을 중요하게 생각하는 이유는 Segmentation에 대한 내용이기 때문이다. Segmentation은 Input Data의 공간정보를 
        잘 유지해야되기 때문이다.
        :: Input Data -> 1) Classification Info, 2) Spatial Dimension Info
           Fully Connected Layer - > 1번이 중요
           Fully Convolutional Network -> 2번이 중요
     2) Skip Architecture
        Fully Convolutional Network의 Feature는 대강의 위치정보만을 가지고 있고 상세한 정보를 지니지 않기 때문에 사용되는 방법이다. 
        (1) 하나의 Fully Convolutional Network만을 사용하는 경우 
            - DeConvolution 후 Upsampled의 결과는 Coarse한 즉, 세부적인 정보를 표현하지 못한다. 대략적인 어느물체가 어디에 있다는 정도만 나타난다.
              따라서 Segmentation을 진행하기에 부족한 모습을 보인다. 
        (2) Skip Architecture에 따라 여러개의 Pooling Layer 별 Fully Convolutional Network를 사용한 경우
            - fine한 세부 정보를 얻기 위해 사용된다 .
            - 세부 정보를 얻기 위하여 이전 단계에서 발생된 Feature들을 Upsampling하고 합쳐주는 방법으로 정보를 보완한다. 
            1) Input Image -> Pool1 ((Input Image)/2의 Dimension을 갖는다.)
            2) Pool1 -> Pool2 ((Pool1)/2 = (Input Image)/4의 Dimension을 갖는다.) 
            3) Pool4 -> Pool5 (Pool4)/2 = (Input Image)/32 = 1 Dimension을 결과로 갖는다. 
            
            4) FCN-32s는 Pool5에 Fully Convolutional Network으로 Upsampling하고 Stride를 32로 갖는다. 
            5) FCN-16s는 Conv7의 결과를 2배로 Upsampling을 한 뒤 이전 Pool4의 결과와 합친 후 16 Stride로 Upsampling 한다. 
            6) FCN-8s는 Conv7 결과 2배, Pool4 결과 2배, Pool3의 결과를 합친 후 8 Stride로 Upsampling 한다. 
        
2. Fully Convolutonal Network
   - 마지막단에 Fully Connected Layer를 Fully Convolutional Network로 변경함에 따라 원본이미지에서 분류된 객체의 위치 정보값이 잘 분포하도록 한다.
     1) AlexNet 기반. 96 -> 256 -> 384 -> 384 -> 256 채널을 확장하는 5단계의 Feature Extract 부분
     2) 4096 -> 4096 -> 21 3단계의 Fully Convolutional Network 
     3) PixelWise Prediction (Skip Architecture가 포함됨) -> Segmentation
     **PatchWise Sampling이 무엇인가**
   
     
        
