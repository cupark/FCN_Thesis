1. Key Insight
   - 이미지 사이즈를 인풋으로 넣었을 때 그에 상응하는 사이즈의 아웃풋을 생성하는 Fully Convolutional Network이다.
   - 기존의 Classification 모델(Pretrained Model)에서 앞단은 그대로 재활용하나 뒷단의 Fully Connected Layer를 거치지 않고 
     Fully Convolutional Network를 거친다. 따라서 이미지의 분류를 라벨링에 대한 분류가 아닌 공간에 대한 분류를 갖게되는 것이다. 
   - 특징
     1) Spatial Dimension
        AlexNet, VGGNet을 그대로 이용하나 Layer의 하위 단에 Fully Connected Layer 대신 Fully Convolutional Network를 사용한다.
        위와 같은 방식을 통하여 Input Data의 Spatial Dimension에 대하여 상응하는 정보를 유지하고자 하였다ㅏ. 
        여기서 Spatial Dimension을 중요하게 생각하는 이유는 Segmentation에 대한 내용이기 때문이다. Segmentation은 Input Data의 공간정보를 
        잘 유지해야되기 때문이다.
        :: Input Data -> 1) Classification Info, 2) Spatial Dimension Info
           Fully Connected Layer - > 1번이 중요
           Fully Convolutional Network -> 2번이 중요
     2) Skip Architecture
        Fully Convolutional Network의 Feature는 대강의 위치정보만을 가지고 있고 상세한 정보를 지니지 않기 때문에 사용되는 방법이다. 
        
2. Fully Convolutonal Network
   - 마지막단에 Fully Connected Layer를 Fully Convolutional Network로 변경함에 따라 원본이미지에서 분류된 객체의 위치 정보값이 잘 분포하도록 한다.
     1) AlexNet 기반. 96 -> 256 -> 384 -> 384 -> 256 채널을 확장하는 5단계의 Feature Extract 부분
     2) 4096 -> 4096 -> 21 3단계의 Fully Convolutional Network 
     3) PixelWise Prediction (Skip Architecture가 포함됨) -> Segmentation
     **PatchWise Sampling이 무엇인가**
     
        
